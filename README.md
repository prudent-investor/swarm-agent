# Agent Swarm Platform

A production-ready multi-agent platform that orchestrates router, knowledge, support, and human hand-off agents to answer InfinitePay customer questions. The solution couples a FastAPI backend, a modern React frontend, and a Retrieval Augmented Generation (RAG) pipeline that ingests the official product website.

## Repository Layout

| Path | Description |
| --- | --- |
| `agent-workflow/` | FastAPI backend, agents, guardrails, observability stack, RAG tooling, and automated tests. |
| `frontend/` | Vite + React + TypeScript interface that surfaces chat, status, and metrics dashboards. |
| `app/` | Lightweight helpers for running the standalone RAG tooling outside the service. |
| `data/` | Persisted artefacts generated by the ingestion pipeline (raw pages, chunks, embeddings, manifests). |
| `Dockerfile.backend` / `Dockerfile.frontend` | Container images for the backend API and the static frontend bundle. |
| `docker-compose.yml` | Local topology that wires backend and frontend with shared network and volume mounts. |

## Architecture Overview

### Message Topology

1. `POST /chat` receives the user payload and normalises it through the Guardrails service (prompt-injection filtering, PII masking, moderation, and quota validation).
2. The RouterAgent classifies the intent (knowledge, support, custom, or Slack hand-off). When the confidence drops below the configured threshold, it triggers a redirect response instead of contacting downstream agents.
3. The selected agent processes the request:
   * **KnowledgeAgent v2** enriches the prompt with context from the local RAG index (and optional web search) and always replies with citations.
   * **CustomerSupportAgent v2** combines FAQ retrieval, ticket creation, policy decisions, and escalation heuristics using dedicated tools.
   * **CustomAgent** provides a safe fallback for off-topic conversations.
   * **SlackAgent** confirms or executes human escalations by coordinating with the in-memory hand-off flow and Slack client stub.
4. Responses propagate telemetry (`correlation_id`, latency buckets, guardrail flags) and are exported through the Prometheus registry for `GET /metrics`.

### Agent Responsibilities

| Agent | Scope | Tooling |
| --- | --- | --- |
| RouterAgent | Intent detection, OpenAI-backed classification with deterministic JSON output, language normalisation, and manual fallbacks. | `app/agents/router_agent.py` |
| KnowledgeAgent v2 | Retrieval augmented answers grounded on InfinitePay documentation, caching, heuristics-based re-ranking, and optional web search fallback. | `app/agents/knowledge_agent_v2.py` |
| CustomerSupportAgent v2 | FAQ matcher, ticket generator, policy evaluation (`decide`), and escalation gating with human confirmation. | `app/agents/support_agent_v2.py` + `app/services/support_service.py` |
| CustomAgent | Lightweight templated replies for small talk or unsupported topics. | `app/agents/custom_agent.py` |
| SlackAgent | Human hand-off workflow with confirmation tokens, Slack payload formatting, and retry-aware metrics. | `app/agents/slack_agent.py` |

### Guardrails & Safety Layer

The Guardrails service strips accents/symbols, blocks prompt-injection patterns, masks email/phone identifiers, enforces output truncation, and integrates with OpenAI moderation models. Diagnostics are exposed through `GET /guardrails/diagnostics` when enabled.

### Observability & Operations

* Structured JSON logging with correlation identifiers for every request.
* Prometheus metrics covering per-agent request counters, latency histograms, redirect totals, and guardrail violations (`agent-workflow/app/observability/metrics.py`).
* Readiness and health endpoints that monitor CPU/memory thresholds and bootstrapping state.
* Redirect engine that issues human hand-off tickets when guardrails escalate or router confidence is too low.

## Retrieval Augmented Generation

The ingestion pipeline ingests InfinitePay public pages (see `data/rag/sources/seed_urls.txt`) and produces artefacts consumed by the KnowledgeAgent:

1. **Load** – Crawl whitelisted URLs with configurable depth, timeout, and request pacing.
2. **Clean** – Strip navigation chrome, deduplicate paragraphs, and hash content for idempotency.
3. **Split** – Chunk documents with overlap; compute metadata including titles, order, and canonical URLs.
4. **Embed** – Generate embeddings via OpenAI (`text-embedding-3-small`) and persist them alongside cleaned text.
5. **Index** – Produce manifest JSONL files, caches, and hashed chunk registries under `data/rag/index/`.

`python scripts/run_rag_dry_run.py` executes offline until the split step, while `python scripts/run_rag_pipeline.py` runs the full pipeline (requires network access and valid OpenAI credentials). The KnowledgeAgent leverages heuristic reranking (`title_boost`, `exact_term_boost`, `length_penalty`), query caching with TTL, fallback messaging, and optional web search to satisfy low-recall scenarios.

## Frontend Experience

The React single-page application offers three core surfaces:

* **Chat Console** – Conversation view with agent-specific styling, clickable citations, correlation IDs, clipboard shortcuts, and localStorage persistence (`frontend/src/components/Chat.tsx`).
* **Status Page** – Visualises `/health` and `/readiness` payloads, including JSON payload dumps and status indicators (`frontend/src/pages/Status.tsx`).
* **Metrics Page** – Streams the raw Prometheus exposition with manual refresh and export-ready formatting (`frontend/src/pages/Metrics.tsx`).

TailwindCSS powers the visual system, while Vite handles development and production builds.

## Deployment Topologies

| Scenario | Description |
| --- | --- |
| Local development | Run FastAPI with Uvicorn and the React dev server independently. Ideal for rapid iteration and unit testing. |
| Docker Compose | `docker compose up --build` launches backend and frontend containers on a shared `agentnet` bridge network, persisting RAG artefacts to `./data`. |
| Standalone images | `Dockerfile.backend` exposes `uvicorn app.main:app --host 0.0.0.0 --port 8000`, while `Dockerfile.frontend` bundles the static site behind Nginx on port `80`. Suitable for Render, Vercel, or other managed platforms. |

## Build & Run Instructions

### Backend (FastAPI)

```bash
cd agent-workflow
python -m venv .venv
source .venv/bin/activate  # Windows: .\.venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env
uvicorn app.main:app --reload
```

`/docs`, `/health`, `/readiness`, `/route`, `/chat`, and `/metrics` become available once the server boots.

### Frontend (React)

```bash
cd frontend
npm install
cp .env.example .env  # optional; defaults to http://127.0.0.1:8000
npm run dev  # opens http://localhost:5173
```

To produce a distributable bundle, execute `npm run build` and optionally `npm run preview` to verify the generated `dist/` output.

### Docker

```bash
docker compose up --build
```

This command builds both images, starts the backend on `http://localhost:8000`, and serves the frontend via Nginx on `http://localhost`. To stop the stack run `docker compose down` (add `-v` to prune volumes). Individual images can be built with:

```bash
docker build -f Dockerfile.backend -t agent-backend .
docker build -f Dockerfile.frontend -t agent-frontend .
```

## Testing Strategy

* **FastAPI + Agents** – `pytest` suite covering health checks, routing logic, guardrails, metrics, persistence, and the RAG admin endpoints (`agent-workflow/tests/`). OpenAI calls are stubbed to keep tests deterministic and offline.
* **RAG Pipeline** – Unit tests validate chunking, manifest creation, and persistence across the ingestion pipeline.
* **Frontend** – Manual verification via Storybook-like dev server; the build step is exercised through CI by `npm run build`.

Execute backend tests with:

```bash
cd agent-workflow
pytest
```

## Challenge Coverage

| Requirement (case proposal) | Implementation |
| --- | --- |
| Three distinct agents orchestrated by a router | RouterAgent dispatches to KnowledgeAgent, CustomerSupportAgent, CustomAgent, and SlackAgent with correlation-aware telemetry. |
| Knowledge agent grounded on InfinitePay content | RAG pipeline ingests the listed URLs and the KnowledgeAgent answers with mandatory citations and web-search fallback. |
| Customer support agent with tooling | SupportService wraps FAQ search, ticket management, policy decisions, and escalation prompts, exposing extra metadata for hand-offs. |
| HTTP API entry point | `POST /chat` accepts `{ "message": str, "user_id": Optional[str] }` and returns JSON with agent, content, citations, and metadata. |
| Dockerisation | Dedicated Dockerfiles and Compose topology orchestrate backend + frontend containers with shared network and persisted data. |
| Testing strategy | Comprehensive pytest suite exercises routing, guardrails, metrics, and RAG components, described in this README and in `agent-workflow/README.md`. |
| Bonus challenges | SlackAgent handles human hand-off confirmation, Guardrails enforce safe prompting and PII masking, and redirect logic escalates low-confidence routes. |

## Further Enhancements

* Plug an actual Slack API client and ticketing integration in place of the in-memory stubs.
* Expand the frontend with automated tests (Vitest/Testing Library) and screenshot baselines.
* Introduce horizontal scaling guidelines (Redis cache for RAG queries, distributed tracing via OpenTelemetry exporters).
* Extend the RAG whitelist with marketing campaigns while preserving guardrail filters and per-source versioning.

For backend internals and environment variable reference see [`agent-workflow/README.md`](agent-workflow/README.md).
- **Validacao manual**: 1) enviar caso critico em /chat ? resposta pede confirmacao ? responder sim com handoff_token ? meta retorna handoff_status="ok" e handoff_message_id; 2) enviar “Quero falar com humano” ? confirmacao ? SlackAgent executa; acompanhar logs slack.handoff.* sem PII.
